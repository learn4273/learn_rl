{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d0f84a7",
   "metadata": {},
   "source": [
    "# Deep Q-Network on CartPole-v1\n",
    "Train a simple DQN using PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2620ffac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import deque\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b1a135",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(state_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, action_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842639d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\")\n",
    "state_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.n\n",
    "policy_net = QNetwork(state_dim, action_dim)\n",
    "target_net = QNetwork(state_dim, action_dim)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d826bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define experience replay buffer and training loop here..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fc38fe",
   "metadata": {},
   "source": [
    "Now implement the training loop using experience replay and target network update."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
